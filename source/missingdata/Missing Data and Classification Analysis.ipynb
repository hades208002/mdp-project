{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing data and classification analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classifiers that provide a prediction probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostingClassifier()\n",
    "DecisionTreeClassifier()\n",
    "RandomForestClassifier()\n",
    "LinearDiscriminantAnalysis()\n",
    "LogisticRegression()\n",
    "KNeighborsClassifier()\n",
    "GaussianNB()\n",
    "ExtraTreesClassifier()\n",
    "BaggingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fancyimpute\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier # PROBABILITY\n",
    "from sklearn.tree import DecisionTreeClassifier # PROBABILITY\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier # PROBABILITY\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier # PROBABILITY\n",
    "from sklearn.linear_model import LogisticRegression # PROBABILITY\n",
    "from sklearn.naive_bayes import GaussianNB # PROBABILITY\n",
    "from sklearn.ensemble import ExtraTreesClassifier # PROBABILITY\n",
    "from sklearn.neighbors import KNeighborsClassifier # PROBABILITY\n",
    "from sklearn.ensemble import BaggingClassifier # PROBABILITY\n",
    "\n",
    "\n",
    "class dataTest:\n",
    "    \n",
    "    ## to be used if you want to test and train on a very specific dataset\n",
    "    ## after this initialization use -> train() and predict()\n",
    "    def __init__(self, X, target,test_size = 0.33, random_state = 12345678, k_fold = 5):\n",
    "        \n",
    "        \n",
    "        \n",
    "        # create test and training sets\n",
    "        train_x, test_x, train_y, test_y = model_selection.train_test_split(X, target, test_size=test_size, random_state=random_state)\n",
    "        trainData = pd.concat([train_x,train_y], axis = 1)\n",
    "        test_y = test_y.ravel()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        self.x_train = train_x\n",
    "        self.y_train = train_y\n",
    "        self.x_test = test_x\n",
    "        self.y_test = test_y\n",
    "        self.random_state = random_state\n",
    "        self.models = [] ## list of the models\n",
    "        self.models_definition(self.random_state)\n",
    "        \n",
    "        self.cv_x = X\n",
    "        self.cv_y = target\n",
    "        self.k_fold = k_fold\n",
    " \n",
    "\n",
    "    def crossValidation(self):\n",
    "        # cross validation\n",
    "        print (\"begin cross validation\")\n",
    "        evaluation = []\n",
    "        for i in self.models:\n",
    "            e = model_selection.cross_val_score(i, self.cv_x, self.cv_y, cv=StratifiedKFold(n_splits=self.k_fold,random_state=self.random_state,shuffle=True))\n",
    "            evaluation.append ((round(np.average(e),4) * 100, round(np.std(e),4) * 100))\n",
    "            \n",
    "        print (\"end cross validation\")\n",
    "        df_cv = pd.DataFrame (evaluation)\n",
    "        return df_cv\n",
    "\n",
    "    def models_definition(self,random_state):\n",
    "        \n",
    "        ## here we can tune the paramenters of the models\n",
    "        \n",
    "        self.models.append(AdaBoostClassifier(DecisionTreeClassifier(max_depth=1, random_state = self.random_state),algorithm=\"SAMME\", n_estimators=200))\n",
    "        #self.model.append(RadiusNeighborsClassifier(radius=10.0, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski'))\n",
    "        self.models.append(RidgeClassifier(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, class_weight=None, solver='auto', random_state=self.random_state))\n",
    "        paramsGB = {'n_estimators': 120, 'max_depth': 3, 'subsample': 0.5,'learning_rate': 0.01, 'min_samples_leaf': 1, 'random_state': self.random_state}\n",
    "        self.models.append(GradientBoostingClassifier(**paramsGB))\n",
    "        self.models.append(DecisionTreeClassifier(random_state=self.random_state))\n",
    "        \n",
    "        self.models.append(RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',max_depth=2, max_features='auto', max_leaf_nodes=None,min_impurity_decrease=0.0, min_impurity_split=None,min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,oob_score=False, random_state=self.random_state, verbose=0, warm_start=False))\n",
    "        \n",
    "        self.models.append(LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,solver='svd', store_covariance=False, tol=0.0001))\n",
    "        self.models.append(LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=self.random_state, solver='liblinear', max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1))\n",
    "        self.models.append(KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=1))\n",
    "        self.models.append(GaussianNB())\n",
    "\n",
    "        \n",
    "        self.models.append(ExtraTreesClassifier(n_estimators=250, random_state=self.random_state))        \n",
    "\n",
    "        self.models.append(BaggingClassifier(base_estimator=None, n_estimators=10, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=1, random_state=self.random_state, verbose=0))\n",
    "        \n",
    "        ## add other models ...\n",
    "        \n",
    "               \n",
    "    \n",
    "\n",
    "    def train(self, x_train = 'self_train_x', y_train = 'self_train_y'):\n",
    "        if x_train == 'self_train_x' and y_train == 'self_train_y':\n",
    "            x_train = self.x_train\n",
    "            y_train = self.y_train\n",
    "        \n",
    "        print (\"START TRAINING\")\n",
    "        for i in self.models:\n",
    "            i.fit(x_train,y_train)     \n",
    "        print (\"END TRAINING\")\n",
    "    \n",
    "    \n",
    "    def statistics(self,predicted_y, test_y):\n",
    "        countPerTrue = 0\n",
    "        countParTrue = 0\n",
    "        countPerFalse = 0\n",
    "        countParFalse = 0\n",
    "        result = []\n",
    "        for i in range(test_y.size):\n",
    "            #print (test_y[i],predicted_y[i],\"\\n\")\n",
    "            if (test_y[i] == predicted_y[i]) and (test_y[i]== 1):\n",
    "                countPerTrue += 1\n",
    "            if (test_y[i] == predicted_y[i]) and (test_y[i]== 0):\n",
    "                countParTrue += 1\n",
    "            if (test_y[i] != predicted_y[i]) and (test_y[i]== 1):\n",
    "                countParFalse += 1\n",
    "            if (test_y[i] != predicted_y[i]) and (test_y[i]== 0):\n",
    "                countPerFalse += 1\n",
    "            #print (Y_bal_1_array[i],Y_P_bal_1[i])\n",
    "        result.append(countPerTrue)\n",
    "        result.append(countParTrue)\n",
    "        result.append(countPerFalse)\n",
    "        result.append(countParFalse)\n",
    "        result.append((countPerTrue + countParTrue)/test_y.size) #ACCURACY\n",
    "        result.append(countPerTrue/ (countPerTrue+countPerFalse)) #PRECISION\n",
    "        result.append(countPerTrue/ (countPerTrue+countParFalse)) #RECALL\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def predict(self, x_test = \"self_test_x\", test_y = \"self_test_y\"):\n",
    "        if x_test == \"self_test_x\" and test_y == \"self_test_y\":\n",
    "            x_test = self.x_test\n",
    "            test_y = self.y_test\n",
    "        \n",
    "        prediction = []\n",
    "        \n",
    "        for i in self.models:\n",
    "            prediction.append(self.statistics(i.predict(x_test).ravel(), test_y))\n",
    "        \n",
    "        df_prediction = pd.DataFrame (prediction)\n",
    "        return df_prediction\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/684 with 1 missing, elapsed time: 0.253\n",
      "Imputing row 101/684 with 0 missing, elapsed time: 0.426\n",
      "Imputing row 201/684 with 60 missing, elapsed time: 0.436\n",
      "Imputing row 301/684 with 0 missing, elapsed time: 0.451\n",
      "Imputing row 401/684 with 0 missing, elapsed time: 0.470\n",
      "Imputing row 501/684 with 0 missing, elapsed time: 0.481\n",
      "Imputing row 601/684 with 0 missing, elapsed time: 0.502\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "#import data\n",
    "d = pd.read_pickle('../data/data.pickle')\n",
    "\n",
    "# create balanced dataset\n",
    "Data_pers = d[d['AFclass'] == 'persistierend (>7 Tage, EKV)']\n",
    "Data_paro = d[d['AFclass'] == 'paroxysmal']\n",
    "Data_paro_1 = Data_paro.sample(n=332, random_state = 1234, replace = False)\n",
    "balanced_1 = pd.concat([Data_pers,Data_paro_1])\n",
    "\n",
    "\n",
    "# missing values recover \n",
    "\n",
    "target = \"AFclass\"\n",
    "balanced_1 = balanced_1.drop('Soggetti', axis = 1)\n",
    "balanced_1 = balanced_1.drop('PCneg', axis = 1)\n",
    "balanced_1 = balanced_1.drop('IPG', axis = 1)\n",
    "balanced_1['patsex'] = balanced_1['patsex'].map({'männlich' : 1, 'weiblich' : 0})\n",
    "balanced_1[\"AFclass\"] = balanced_1[\"AFclass\"].map({'persistierend (>7 Tage, EKV)' : 1, 'paroxysmal' : 0}) \n",
    "features = balanced_1.columns[balanced_1.columns != target]\n",
    "x_incomplete = balanced_1[features]\n",
    "y = balanced_1[\"AFclass\"].as_matrix()\n",
    "# impute missing value with KNN strategy\n",
    "x_knn_a = fancyimpute.KNN(15).complete(x_incomplete)\n",
    "x_knn = pd.DataFrame(x_knn_a, columns = features)\n",
    "y_new = pd.DataFrame(y)\n",
    "y_new = y_new.rename(columns = {y_new.columns[0] : 'AFclass'})\n",
    "Data_KNN = pd.concat([x_knn,y_new], axis = 1)\n",
    "balanced_1 = Data_KNN\n",
    "\n",
    "\n",
    "# get target variables \n",
    "X_bal_1 = balanced_1[balanced_1.columns[balanced_1.columns != \"AFclass\"]]\n",
    "Y_bal_1 = balanced_1[\"AFclass\"]\n",
    "\n",
    "\n",
    "# create test and training sets\n",
    "train_x, test_x, train_y, test_y = model_selection.train_test_split(X_bal_1, Y_bal_1, test_size=0.33, random_state=1242)\n",
    "\n",
    "#train_x.shape\n",
    "\n",
    "#trainData = pd.concat([train_x,train_y])\n",
    "#train_y = pd.DataFrame(train_y)\n",
    "trainData = pd.concat([train_x,train_y], axis = 1)\n",
    "trainData.head()\n",
    "test_y = test_y.ravel()\n",
    "#test_y = test_y.map({'persistierend (>7 Tage, EKV)' : 1, 'paroxysmal' : 0})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#g = dataTest(train_x,train_y,test_x,test_y)\n",
    "g = dataTest(X = X_bal_1,target = Y_bal_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START TRAINING\n",
      "END TRAINING\n"
     ]
    }
   ],
   "source": [
    "g.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hh = g.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "      <td>0.548673</td>\n",
       "      <td>0.556452</td>\n",
       "      <td>0.594828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>51</td>\n",
       "      <td>56</td>\n",
       "      <td>0.526549</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.517241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83</td>\n",
       "      <td>49</td>\n",
       "      <td>61</td>\n",
       "      <td>33</td>\n",
       "      <td>0.584071</td>\n",
       "      <td>0.576389</td>\n",
       "      <td>0.715517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>46</td>\n",
       "      <td>64</td>\n",
       "      <td>54</td>\n",
       "      <td>0.477876</td>\n",
       "      <td>0.492063</td>\n",
       "      <td>0.534483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68</td>\n",
       "      <td>61</td>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "      <td>0.570796</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.586207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>51</td>\n",
       "      <td>56</td>\n",
       "      <td>0.526549</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.517241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>63</td>\n",
       "      <td>56</td>\n",
       "      <td>54</td>\n",
       "      <td>53</td>\n",
       "      <td>0.526549</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.543103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>59</td>\n",
       "      <td>68</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>0.561947</td>\n",
       "      <td>0.584158</td>\n",
       "      <td>0.508621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>51</td>\n",
       "      <td>78</td>\n",
       "      <td>32</td>\n",
       "      <td>65</td>\n",
       "      <td>0.570796</td>\n",
       "      <td>0.614458</td>\n",
       "      <td>0.439655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>69</td>\n",
       "      <td>54</td>\n",
       "      <td>56</td>\n",
       "      <td>47</td>\n",
       "      <td>0.544248</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.594828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>48</td>\n",
       "      <td>73</td>\n",
       "      <td>37</td>\n",
       "      <td>68</td>\n",
       "      <td>0.535398</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>0.413793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2   3         4         5         6\n",
       "0   69  55  55  47  0.548673  0.556452  0.594828\n",
       "1   60  59  51  56  0.526549  0.540541  0.517241\n",
       "2   83  49  61  33  0.584071  0.576389  0.715517\n",
       "3   62  46  64  54  0.477876  0.492063  0.534483\n",
       "4   68  61  49  48  0.570796  0.581197  0.586207\n",
       "5   60  59  51  56  0.526549  0.540541  0.517241\n",
       "6   63  56  54  53  0.526549  0.538462  0.543103\n",
       "7   59  68  42  57  0.561947  0.584158  0.508621\n",
       "8   51  78  32  65  0.570796  0.614458  0.439655\n",
       "9   69  54  56  47  0.544248  0.552000  0.594828\n",
       "10  48  73  37  68  0.535398  0.564706  0.413793"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each row corresponds to a classifier, the columns 4,5,6 are (respectively) the ACCURACY,PREDICTION AND RECALL\n",
    "\n",
    "\n",
    "hh.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin cross validation\n",
      "end cross validation\n"
     ]
    }
   ],
   "source": [
    "cv = g.crossValidation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.16</td>\n",
       "      <td>1.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.43</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.56</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.89</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58.34</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55.28</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>55.71</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54.38</td>\n",
       "      <td>2.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54.97</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>56.72</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>53.35</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1\n",
       "0   57.16  1.82\n",
       "1   55.43  3.25\n",
       "2   56.56  2.92\n",
       "3   51.89  3.60\n",
       "4   58.34  1.02\n",
       "5   55.28  3.21\n",
       "6   55.71  2.93\n",
       "7   54.38  2.81\n",
       "8   54.97  2.18\n",
       "9   56.72  1.07\n",
       "10  53.35  3.15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
